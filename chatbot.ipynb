{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhd/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xhd/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xhd/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xhd/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xhd/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xhd/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files and Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1045</th>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1044</th>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L985</th>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L984</th>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L925</th>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1   2        3             4\n",
       "0                                   \n",
       "L1045  u0  m0   BIANCA  They do not!\n",
       "L1044  u2  m0  CAMERON   They do to!\n",
       "L985   u0  m0   BIANCA    I hope so.\n",
       "L984   u2  m0  CAMERON     She okay?\n",
       "L925   u0  m0   BIANCA     Let's go."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_path = 'data/movie_lines.txt'\n",
    "convs_path = 'data/movie_conversations.txt'\n",
    "\n",
    "lines_df = pd.read_csv(lines_path,\n",
    "                    sep='\\s*\\+\\+\\+\\$\\+\\+\\+\\s*', \n",
    "                    engine='python',\n",
    "                    header=None,\n",
    "                    index_col=0)\n",
    "\n",
    "lines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      0\n",
       "2      0\n",
       "3     43\n",
       "4    267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_df.iloc[:, -1].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0\n",
       "2     0\n",
       "3    43\n",
       "4     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L194', 'L195', 'L196', 'L197']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L198', 'L199']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L200', 'L201', 'L202', 'L203']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L204', 'L205', 'L206']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L207', 'L208']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2                                 3\n",
       "0  u0  u2  m0  ['L194', 'L195', 'L196', 'L197']\n",
       "1  u0  u2  m0                  ['L198', 'L199']\n",
       "2  u0  u2  m0  ['L200', 'L201', 'L202', 'L203']\n",
       "3  u0  u2  m0          ['L204', 'L205', 'L206']\n",
       "4  u0  u2  m0                  ['L207', 'L208']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convs_df = pd.read_csv(convs_path,\n",
    "                    sep='\\s*\\+\\+\\+\\$\\+\\+\\+\\s*', \n",
    "                    engine='python',\n",
    "                    header=None)\n",
    "\n",
    "convs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convs_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2dfbcce0bbb4a69b55a154c9ccb7757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Build', max=83097, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convs_data = []\n",
    "for line_ids in tqdm(convs_df.iloc[:, -1], desc='Build'):\n",
    "    conv = []\n",
    "    for line_id in eval(line_ids):\n",
    "        conv.append(lines_df.loc[line_id].iloc[-1])\n",
    "    convs_data.append(conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Check Length of Conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = [len(conv) for conv in convs_data]\n",
    "plt.hist(lens, bins=30)\n",
    "plt.ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Each Sentence and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sent):\n",
    "    sent = sent.lower().strip()\n",
    "    sent = re.sub(r'[^a-zA-Z.!?]+', r' ', sent)\n",
    "    sent = re.sub(r'([.!?])\\1*', r' \\1', sent)\n",
    "    sent = re.sub(r'\\s+', r' ', sent)\n",
    "    sent = sent.strip().split()\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e74fb39e0044d8b8477a5b9a62c47ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Clean', max=83097, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convs = []\n",
    "for conv in tqdm(convs_data, desc='Clean'):\n",
    "    convs.append(list(map(clean, conv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Check Length of Each Sentence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = []\n",
    "for conv in convs:\n",
    "    for sent in conv:\n",
    "        lens.append(len(sent))\n",
    "plt.hist(lens, bins=50)\n",
    "plt.ylim(0, 5000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281094 304713 0.9224877179509899\n"
     ]
    }
   ],
   "source": [
    "lens_short = [x for x in lens if x <= 30]\n",
    "print(len(lens_short), len(lens), len(lens_short) / len(lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Sentence Pairs and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221616\n"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "for conv in convs:\n",
    "    for i in range(len(conv) - 1):\n",
    "        pairs.append((conv[i], conv[i + 1]))\n",
    "        \n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188774\n",
      "['can', 'we', 'make', 'this', 'quick', '?', 'roxanne', 'korrine', 'and', 'andrew', 'barrett', 'are', 'having', 'an', 'incredibly', 'horrendous', 'public', 'break', 'up', 'on', 'the', 'quad', '.', 'again', '.']\n",
      "['well', 'i', 'thought', 'we', 'd', 'start', 'with', 'pronunciation', 'if', 'that', 's', 'okay', 'with', 'you', '.']\n"
     ]
    }
   ],
   "source": [
    "def filter_pairs(pairs, min_length):\n",
    "    pairs_short = []\n",
    "    for a, b in pairs:\n",
    "        if len(a) > 0 and len(a) <= MIN_LENGTH \\\n",
    "            and len(b) > 0 and len(b) <= MIN_LENGTH:\n",
    "            pairs_short.append((a, b))\n",
    "    return pairs_short\n",
    "\n",
    "\n",
    "MIN_LENGTH = 30\n",
    "pairs = filter_pairs(pairs, MIN_LENGTH)\n",
    "\n",
    "print(len(pairs))\n",
    "print(pairs[0][0])\n",
    "print(pairs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.',\n",
       " \"Well, I thought we'd start with pronunciation, if that's okay with you.\",\n",
       " 'Not the hacking and gagging and spitting part.  Please.',\n",
       " \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convs_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.special_tokens = ['<pad>', '<eos>', '<unk>']\n",
    "        self.word_count = {}\n",
    "        self.index2word = []\n",
    "        self.word2index = {}\n",
    "        \n",
    "    def add_word(self, word):\n",
    "        if word in self.word_count:\n",
    "            self.word_count[word] += 1\n",
    "        else:\n",
    "            self.word_count[word] = 1\n",
    "            \n",
    "    def make_vocab(self, size):\n",
    "        self.word_count = sorted(self.word_count, key=self.word_count.get, reverse=True)\n",
    "     \n",
    "        for w in self.special_tokens + self.word_count[:size]:\n",
    "            self.index2word.append(w)\n",
    "            self.word2index[w] = len(self.index2word) - 1\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.index2word)\n",
    "                \n",
    "    def __getitem__(self, query):\n",
    "        if isinstance(query, int):\n",
    "            return self.index2word[query]\n",
    "        if isinstance(query, str):\n",
    "            if query in self.word2index:\n",
    "                return self.word2index[query]\n",
    "            else:\n",
    "                return self.word2index['<unk>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Test Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 3, 'boy': 2, 'cow': 1, 'and': 1}\n",
      "['<pad>', '<eos>', '<unk>', 'a', 'boy', 'cow']\n",
      "{'<pad>': 0, '<eos>': 1, '<unk>': 2, 'a': 3, 'boy': 4, 'cow': 5}\n",
      "6\n",
      "boy\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = ['a', 'boy', 'cow', 'and', 'a', 'boy', 'a']\n",
    "\n",
    "vocab = Vocab()\n",
    "for word in a:\n",
    "    vocab.add_word(word)\n",
    "print(vocab.word_count)\n",
    "\n",
    "vocab.make_vocab(size=3)\n",
    "\n",
    "print(vocab.index2word)\n",
    "print(vocab.word2index)\n",
    "print(len(vocab))\n",
    "print(vocab[4])\n",
    "print(vocab['<eos>'])\n",
    "print(vocab['abc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Vocabuary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41034\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab()\n",
    "for i in range(len(pairs) - 1):\n",
    "    if pairs[i][1] == pairs[i + 1][0]:\n",
    "        words = pairs[i][0]\n",
    "    else:\n",
    "        words = pairs[i][0] + pairs[i][1]\n",
    "    for word in words:\n",
    "        vocab.add_word(word)\n",
    "        \n",
    "print(len(vocab.word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Check Word Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = sorted(vocab.word_count.values(), reverse=True)\n",
    "plt.plot(a)\n",
    "plt.ylim(0, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(a[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "vocab.make_vocab(size=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10003"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, pairs, vocab):\n",
    "        self.pairs = pairs\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.pairs[index]\n",
    "        x = [vocab[w] for w in x]\n",
    "        y = [vocab[w] for w in y] + [vocab['<eos>']]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188774\n",
      "['can', 'we', 'make', 'this', 'quick', '?', 'roxanne', 'korrine', 'and', 'andrew', 'barrett', 'are', 'having', 'an', 'incredibly', 'horrendous', 'public', 'break', 'up', 'on', 'the', 'quad', '.', 'again', '.']\n",
      "[39, 20, 115, 26, 886, 6, 2, 2, 17, 4306, 6942, 37, 418, 85, 3831, 2, 1189, 496, 57, 35, 7, 2, 3, 185, 3]\n",
      "['well', 'i', 'thought', 'we', 'd', 'start', 'with', 'pronunciation', 'if', 'that', 's', 'okay', 'with', 'you', '.']\n",
      "[61, 5, 144, 20, 78, 323, 41, 2, 55, 13, 9, 107, 41, 4, 3, 1]\n",
      "['<pad>', '<eos>', '<unk>', '.', 'you', 'i', '?', 'the', 'to', 's', 'it', 'a', 't', 'that', 'what', '!', 'of', 'and', 'me', 'in']\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(pairs, vocab)\n",
    "\n",
    "print(len(dataset))\n",
    "print(pairs[0][0])\n",
    "print(dataset[0][0])\n",
    "print(pairs[0][1])\n",
    "print(dataset[0][1])\n",
    "print(vocab.index2word[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [2, 0],\n",
      "        [3, 0]])\n",
      "tensor([[1, 1],\n",
      "        [2, 2],\n",
      "        [0, 3]])\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    batch_x, batch_y = [], []\n",
    "    for x, y in batch:\n",
    "        batch_x.append(torch.tensor(x))\n",
    "        batch_y.append(torch.tensor(y))\n",
    "    batch_x = torch.nn.utils.rnn.pad_sequence(batch_x, padding_value=0)    \n",
    "    batch_y = torch.nn.utils.rnn.pad_sequence(batch_y, padding_value=0)\n",
    "    return batch_x, batch_y\n",
    "\n",
    "\n",
    "batch = [\n",
    "    ([1, 2, 3], [1, 2]),\n",
    "    ([1], [1, 2, 3]),\n",
    "]\n",
    "\n",
    "batch_x, batch_y = collate_fn(batch)\n",
    "print(batch_x)\n",
    "print(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = batch_x\n",
    "\n",
    "((x != 0).sum(dim=0) <= 2).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, \n",
    "    batch_size=4,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 4])\n",
      "torch.Size([17, 4])\n"
     ]
    }
   ],
   "source": [
    "a = next(iter(data_loader))\n",
    "print(a[0].shape)\n",
    "print(a[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 4, 8]) torch.Size([4, 4]) torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, embed, hidden_size, pad_value):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.pad_value = pad_value\n",
    "        self.embed = embed\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=embed.embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lengths = (x != self.pad_value).sum(dim=0)\n",
    "        x = self.embed(x)\n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            x, lengths, enforce_sorted=False)\n",
    "        output, (h, c) = self.lstm(x)\n",
    "        output, _ = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            output, padding_value=self.pad_value)\n",
    "        return output, (h.mean(dim=0), c.mean(dim=0))\n",
    "\n",
    "    \n",
    "vocab_size = 10\n",
    "embed_size = 5\n",
    "batch_size = 4\n",
    "hidden_size = 4\n",
    "\n",
    "embed = torch.nn.Embedding(len(vocab), embed_size)\n",
    "encoder = Encoder(embed, hidden_size, pad_value=0)\n",
    "batch_x, batch_y = next(iter(data_loader))\n",
    "contex, (h, c) = encoder(batch_x)\n",
    "print(contex.shape, h.shape, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, embed, hidden_size, start_token):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.start_token = start_token\n",
    "        self.embed = embed\n",
    "        self.lstm_cell = torch.nn.LSTMCell(\n",
    "            embed.embedding_dim, hidden_size)\n",
    "        self.out = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2 * hidden_size, hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_size, embed.num_embeddings),\n",
    "        )\n",
    "        \n",
    "    def forward(self, hidden, contex, y):\n",
    "        y_preds = []\n",
    "        h, c = hidden\n",
    "        x = torch.empty(*y.size()[1:], dtype=torch.long)\n",
    "        x = x.fill_(self.start_token)\n",
    "        for i in range(len(y)):\n",
    "            x = self.embed(x)\n",
    "            h, c = self.lstm_cell(x, (h, c))\n",
    "            y_pred = self.out(torch.cat([h, c], dim=1))\n",
    "            y_preds.append(y_pred)\n",
    "            x = y[i]\n",
    "        return torch.stack(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, \n",
    "                 pad_value, start_token):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(vocab_size, embed_size)\n",
    "        self.encoder = Encoder(embed, hidden_size, pad_value)\n",
    "        self.decoder = Decoder(embed, hidden_size, start_token)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        contex, (h, c) = self.encoder(x)\n",
    "        y_preds = self.decoder((h, c), contex, y)\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37d96e014e642dfb747812a8ce156a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Total', max=2, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce352ecd73449dbad972459dfb70428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train Epoch 0', max=47194, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-e6834ec0c7a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;31m# trainer.overfit_one_batch(800)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-e6834ec0c7a6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Total'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dataloader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-e6834ec0c7a6>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Train Epoch {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-e6834ec0c7a6>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, model, train_dataloader, n_epoch, optim, tb_dir=None, \n",
    "                 case_interval=None, vocab=None,\n",
    "                 valid_dataloader=None, test_dataloader=None):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.n_epoch = n_epoch\n",
    "        self.optim = optim\n",
    "        self.case_interval = case_interval\n",
    "        self.vocab = vocab\n",
    "        self.writer = SummaryWriter(tb_dir, flush_secs=1) if tb_dir else None\n",
    "        \n",
    "    def loss_fn(self, input, target):\n",
    "        input = input.reshape(-1, input.size(-1))\n",
    "        target = target.reshape(-1)\n",
    "        \n",
    "        loss = torch.nn.functional.cross_entropy(\n",
    "            input=input, target=target,\n",
    "            ignore_index=0, reduction='mean')\n",
    "        return loss\n",
    "    \n",
    "    def batch2sents(self, batch):\n",
    "        sents = []\n",
    "        for data in batch.tolist():\n",
    "            for _ in range(data.count(0)):\n",
    "                data.remove(0)\n",
    "            if data == []:\n",
    "                data.append('<pad> ...')\n",
    "            sent = [self.vocab[x] for x in data]\n",
    "            sents.append(' '.join(sent))\n",
    "        return sents\n",
    "    \n",
    "    def show_case(self, x, y, y_preds, step):\n",
    "        post = self.batch2sents(x.T)[1]\n",
    "        targ = self.batch2sents(y.T)[1]\n",
    "        pred = y_preds.argmax(dim=2)\n",
    "        pred = self.batch2sents(pred.T)[1]\n",
    "        texts = [\n",
    "            f'[Post] {post}',\n",
    "            f'[Targ] {targ}',\n",
    "            f'[Pred] {pred}'\n",
    "        ]\n",
    "        self.writer.add_text('case', '\\n\\n'.join(texts), step)\n",
    "        \n",
    "    def train_batch(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_preds = self.model(x, y)\n",
    "        loss = self.loss_fn(input=y_preds, target=y)\n",
    "        self.model.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            self.show_case(x, y, y_preds, batch_idx)\n",
    "        return {'loss': loss.item()}\n",
    "        \n",
    "    def overfit_one_batch(self, n_step):\n",
    "        self.model.train()\n",
    "        batch = next(iter(self.train_dataloader))\n",
    "        pbar = tqdm(range(n_step), desc='Overfit')\n",
    "        for i in pbar:\n",
    "            state = self.train_batch(batch, i)\n",
    "            pbar.set_postfix(state)\n",
    "            if self.writer is not None:\n",
    "                self.writer.add_scalars('overfit', state, i)\n",
    "            \n",
    "    def fit(self): \n",
    "        for epoch in tqdm(range(self.n_epoch), desc='Total'):\n",
    "            self.train_epoch(epoch)\n",
    "            if self.valid_dataloader is not None:\n",
    "                self.valid_epoch(epoch)\n",
    "            if self.test_dataloader is not None:\n",
    "                self.test_epoch(epoch)\n",
    "                \n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        pbar = tqdm(self.train_dataloader, desc=f'Train Epoch {epoch}')\n",
    "        for idx, batch in enumerate(pbar):\n",
    "            state = self.train_batch(batch, idx)\n",
    "            pbar.set_postfix(state)\n",
    "            if self.writer is not None:\n",
    "                self.writer.add_scalars('train', state, idx)\n",
    "\n",
    "            \n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                               batch_size=4, \n",
    "                                               collate_fn=collate_fn)\n",
    "model = Seq2Seq(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_size=100, \n",
    "    hidden_size=100, \n",
    "    pad_value=0, \n",
    "    start_token=1,\n",
    ")\n",
    "adam = torch.optim.Adam(model.parameters())\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    n_epoch=2,\n",
    "    optim=adam,\n",
    "    tb_dir='runs/train7',\n",
    "    case_interval=10,\n",
    "    vocab=vocab,\n",
    ")\n",
    "\n",
    "# trainer.overfit_one_batch(800)\n",
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
